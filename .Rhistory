d$Degree != 'n'
d$Degree == 'n'
d
d <- read.csv('/Users/chengnie/Google Drive/Research/UTD/project/stackoverflow/data/sum/stack_linkedin_glassdor2.csv')
summary(d$mean_sal_imp)
d$Reputation_sq <- d$Reputation^2
d$workMonth_sq <- d$workMonth^2
# log transform
d$lmean_sal_imp <- log(d$mean_sal_imp)
d$lReputation <- log(d$Reputation)
d$lworkMonth <- log(d$workMonth)
d$Degree == 'n'
d$Degree <> 'n'
d$Degree != 'n'
(1:dim(d)[1])[d$Dgreee!='n']
(1:dim(d)[1])
[d$Dgreee!='n']
d$Dgreee!='n'
d$Dgreee != 'n'
d$Degree != 'n'
(1:dim(d)[1])[d$Degree!='n']
fit3_4 <- lm(lmean_sal_imp ~ lReputation + lworkMonth + Degree, data = d, subset = (1:dim(d)[1])[d$Degree!='n'])
fit3_5 <- lm(lmean_sal_imp ~ lReputation + lworkMonth + Degree, data = d, subset = (1:dim(d)[1])[d$Degree!='n'])
summary(fit3_5)
quantile(d$Reputation,c(.32, .57, .98))
quantile(d$Reputation,c(.33, .66))
sum(d$Reputation<389.84)
sum(1980.18>d$Reputation>389.84)
sum(1980.18> d$Reputation and d$Reputation>389.84)
1980.18> d$Reputation
sum(1980.18> d$Reputation & d$Reputation>389.84)
sum(1980.18< d$Reputation) #76
d$RL <- '1'
d$RL [1980.18> d$Reputation & d$Reputation>389.84] <- '2'
d$RL [1980.18 < d$Reputation] <- '3'
table(d$RL)
fit3_6 <- lm(lmean_sal_imp ~ RL + lworkMonth + Degree, data = d])
fit3_6 <- lm(lmean_sal_imp ~ RL + lworkMonth + Degree, data = d)
summary(fit3_6)
install.packages("AER")
install.packages("lmtest")
source('~/Dropbox/svn/R/2sls.R', echo=TRUE)
library(AER)
library(lmtest)
data("CollegeDistance")
cd.d<-CollegeDistance
simple.ed.1s<- lm(education ~ distance,data=cd.d)
cd.d$ed.pred<- predict(simple.ed.1s)
simple.ed.2s<- lm(wage ~ urban + gender + ethnicity + unemp + ed.pred , data=cd.d)
simple.comp<- encomptest(wage ~ urban + gender + ethnicity + unemp + ed.pred , wage ~ urban + gender + ethnicity + unemp + education , data=cd.d)
s1.ftest<- encomptest(education ~ tuition + gender + ethnicity + urban , education ~ distance , data=cd.d)
library(arm)
coefplot(lm(wage ~ urban + gender + ethnicity + unemp + education,data=cd.d),vertical=FALSE,var.las=1,varnames=c("Education","Unemp","Hispanic","Af-am","Female","Urban","Education"))
coefplot(simple.ed.2s , vertical=FALSE,var.las=1,varnames=c("Education","Unemp","Hispanic","Af-am","Female","Urban","Education"))
?ivreg
summary(simple.ed.2s)
table(d$RL)
fit3_6 <- lm(lmean_sal_imp ~ RL + lworkMonth + Degree, data = d)
summary(fit3_6)
sum(d$Reputation >=200)
171/232.
fit3_4 <- lm(lmean_sal_imp ~ lReputation + lworkMonth + Degree, data = d)
summary(fit3_4)
mean(d$mean_sal_imp[d$Reputation>923.5])
mean(d$mean_sal_imp[d$Reputation<923.5])
library(foreign)
d <- read.dta("/Users/chengnie/Google Drive/sync/math/econometrics/wooldridge_4e/stata/vote1.DTA",convert.factors = FALSE)
d$expendAB <- d$expendA * d$expendB
fit1 <- lm(voteA ~ prtystrA + expendA + expendB + expendAB, data = d)
summary(fit1)
mean(d$expendA)
310*6.6*e-6
310*6.6*10^(-6)
fit2 <- lm(voteA ~ prtystrA + expendA + expendB + shareA, data = d)
summary(fit2)
library(foreign)
d <- read.dta("/Users/chengnie/Google Drive/sync/math/econometrics/wooldridge_4e/stata/401ksubs.DTA",convert.factors = FALSE)
summary(d$nettfa)
sd(d$nettfa)
fit1 <- lm(nettfa ~ p401k, data=d)
summary(fit1)
fit1 <- lm(nettfa ~ e401k, data=d)
summary(fit1)
source('~/Dropbox/svn/R/unobserved_effects.R', echo=TRUE)
source('~/Dropbox/svn/R/unobserved_effects.R', echo=TRUE)
source('~/Dropbox/svn/R/unobserved_effects.R', echo=TRUE)
source('~/Dropbox/svn/R/unobserved_effects.R', echo=TRUE)
out3 <- lm(y~x+factor(id)+factor(t), data=fulldata)
coefficients(out3)['x']
fulldata$privacy <- 0
fulldata$privacy[fulldata$t == 4 or fulldata$t ==5] <- 1
fulldata$privacy[fulldata$t == 4] <- 1
fulldata$privacy[fulldata$t == 5] <- 1
out4 <- lm(y~x+privacy+factor(id)+factor(t), data=fulldata)
coefficients(out4)['x']
nobs
nperson
fulldata$age <- 1:nobs*nperson
out5 <- lm(y~x+privacy+age+factor(id)+factor(t), data=fulldata)
coefficients(out5)['x']
library(swirl)
swirl()
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)] #gives us all elements of x EXCEPT for the 2nd and 10 elements
x[-c(2, 10)] #gives us all elements of x EXCEPT for the 2nd and 10 elements
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
my_vector <- 1:20
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
matrix(1:20, nrow = 4, ncol = 5)
my_matrix2 <- matrix(1:20, nrow = 4, ncol = 5)
identical(my_matrix, my_matrix2)
pname <- c("Bill", "Gina", "Kelly", "Sean")
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5!= 7
!(5==7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints > 7)
any(ints < 0)
all(ints < 0)
all(ints > 0)
Sys.Date()
mean(c(2, 4, 5))
submit()
boring_function('My first function!')
boring_function()
boring_function
submit()
my_mean(c(4,5,10))
submit()
submit()
submit
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, di = 2)
args(remainder)
submit()
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x){x[1]}, c(8, 4, 0))
evaluate(function(x){x[length(x)]}, c(8, 4, 0))
?paste
paste("programming", "is", "fun!")
paste("Programming", "is", "fun!")
submit()
telegram("test")
submit()
mad_libs(place="Richardson", adjective = "controvertially", noun = "restaurant")
submit()
'I' %p% 'love' %p% 'R!'
head(flags)
dim(flags)
viewinfo()
class(flags)
as.list(flags)
lapply(flags, class)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
?vapply
vapply(flags, unique, numeric(1)) # vapply will do an error check to see if the results of sapply would be numeric(1)
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary) #north america is the highest
tapply(flags$population, flags$landmass, summary) #north america is the highest
ls()
dir()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10, replace = FALSE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
sample(c(0,1), 100, prob = c(0.3, 0.7))
sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, 100, prob = 0.7)
rbinom(100, 100, prob = 0.7)
rbinom(1, 100, prob = 0.7)
rbinom(1, 100, prob = 0.7)
flips2 <- rbinom(100, 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd = 25)
?rpois
rpois(5, 10)
replicate(100, rpois(5, 10))
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time())
t2 <- as.POSIXlt(Sys.time())
t2
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$dist, y=cars$speed)
plot(x=cars$speed, y=cars$dist)
plot(x=cars$dist, y=cars$speed)
plot(x=cars$dist, y=cars$speed)
plot(x=cars$speed, y=cars$dist, xlab = "Speed")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, main = "My Plot")
plot(cars, main = "My Plot")
plot(cars, main = "My Plot", sub = "My Plot Subtitle")
plot(cars, sub = "My Plot Subtitle")
?par
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
?points #to change shape of plots
plot(cars, pch = 2)
data("mtcars")
data(mtcars)
?boxplot
boxplot(mpg~cyl, data = mtcars)
hist(mtcars$mpg)
setwd('/Users/chengnie/Dropbox/code/R/coursera/05_ReproducibleResearch/RepData_PeerAssessment1')
activity <- read.csv('./activity.csv', header = TRUE)
sum(activity$)
str(activity)
library(dplyr)
total_step_per_day <- activity %>% group_by(as.factor(date)) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
hist(total_step_per_day$total_steps)
summary(total_step_per_day$total_steps)
2400/60/60
2400/60
2400*5/60
2360*5/60/60
24*60*60
plot(total_step_per_day)
plot(total_step_per_day, lt = "l")
plot(total_step_per_day, lt = "l")
activity <- read.csv('./activity.csv', header = TRUE)
total_step_per_day <- activity %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
avg_step_per_day <- activity %>% group_by(date) %>% summarize(avg_steps = mean(steps, na.rm = TRUE))
with(avg_step_per_day, plot(date, avg_steps,totallt = "l")
with(avg_step_per_day, plot(date, avg_steps,lt = "l")
with(avg_step_per_day, plot(date, avg_steps,lt = "l")
with(avg_step_per_day, plot(date, avg_steps,lt = "l"))
with(avg_step_per_day, plot(date, avg_steps,lt = "l"))
with(avg_step_per_day, plot(date, avg_steps))
?pch
with(avg_step_per_day, plot(date, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
activity$date[1]
activity$date[2]
as.string(activity$date[2])
as.character(activity$date[2])
activity <- read.csv('./activity.csv', header = TRUE)
# transform the factor date into actual date
activity <- transform(activity, date = strptime(as.character(date), format = "%Y-%m-%d"))
str(activity)
sum(activity$)
total_step_per_day <- activity %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
total_step_per_day <- activity %>% group_by(as.factor(date)) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
activity$date[2]
as.factor(activity$date[2])
as.character(activity$date[2])
total_step_per_day <- activity %>% group_by(as.character(date)) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
total_step_per_day <- activity %>% group_by(as.character(date)) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
total_step_per_day <- activity %>% group_by(as.POSIXct(date)) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
activity <- transform(activity, date = as.POSIXct(strptime(date, format = "%Y-%m-%d")))
str(activity)
total_step_per_day <- activity %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
total_step_per_day <- activity %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
hist(total_step_per_day$total_steps)
summary(total_step_per_day$total_steps)
avg_step_per_day <- activity %>% group_by(date) %>% summarize(avg_steps = mean(steps, na.rm = TRUE))
with(avg_step_per_day, plot(date, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
avg_step_per_interval <- activity %>% group_by(interval) %>% summarize(avg_steps = mean(steps, na.rm = TRUE))
with(avg_step_per_interval, plot(date, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
with(avg_step_per_interval, plot(date, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
with(avg_step_per_interval, plot(interval, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
with(avg_step_per_interval, which(avg_steps = max(avg_steps)))
with(avg_step_per_interval, which(avg_steps == max(avg_steps)))
with(avg_step_per_interval, interval[which(avg_steps == max(avg_steps))])
with(avg_step_per_interval, max(avg_steps)))
with(avg_step_per_interval, max(avg_steps))
with(avg_step_per_interval, avg_steps[interval == 835])
sum(is.na(activity$steps))
288*5/60
activity$interval
as.factor(activity$interval)
for (int in avg_step_per_interval$interval){
activity[is.na(activity$steps) & activity$interval == int] = avg_step_per_interval[avg_step_per_interval==int]
}
for (int in avg_step_per_interval$interval){
print(int)
}
for (int in avg_step_per_interval$interval){
print(activity$steps[is.na(activity$steps) & activity$interval == int]t)
}
for (int in avg_step_per_interval$interval){
print(activity$steps[is.na(activity$steps) & activity$interval == int])
}
for (int in avg_step_per_interval$interval){
}
for (int in avg_step_per_interval$interval){
activity$steps[is.na(activity$steps) & activity$interval == int] = avg_step_per_interval[avg_step_per_interval$interval==int]
}
str(ac)
str(activity)
activity <- read.csv('./activity.csv', header = TRUE)
activity <- transform(activity, date = as.POSIXct(strptime(date, format = "%Y-%m-%d")))
str(activity)
chicago <- readRDS("/Users/chengnie/Google Drive/sync/mooc/DataScienceSpecialization/03_GetData/w3/chicago.rds")
dim(chicago)
head(select(chicago, 1:5)) # only first 5 columns
names(chicago)[1:3]
head(select(chicago, city:dptp)) # use the variable names directly
head(select(chicago, -(city:dptp))) # don't include
chic.f <- filter(chicago, pm25tmean2 > 30)
head(select(chic.f, 1:3, pm25tmean2), 10) # indices and variable names are used at the same time
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(select(chic.f, 1:3, pm25tmean2, tmpd), 10)
activity_copy <- activity
library(dplyr)
#with(activity, tapply(steps, as.factor(date), sum))
total_step_per_day <- activity %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
```
2. If you do not understand the difference between a histogram and a barplot, research the difference between them. Make a histogram of the total number of steps taken each day
hist(total_step_per_day$total_steps)
summary(total_step_per_day$total_steps)
avg_step_per_interval <- activity %>% group_by(interval) %>% summarize(avg_steps = mean(steps, na.rm = TRUE))
with(avg_step_per_interval, plot(interval, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
avg_step_per_day <- activity %>% group_by(date) %>% summarize(avg_steps = mean(steps, na.rm = TRUE))
with(avg_step_per_day, plot(date, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
with(avg_step_per_interval, interval[which(avg_steps == max(avg_steps))])
with(avg_step_per_interval, max(avg_steps))
with(avg_step_per_interval, avg_steps[interval == 835])
sum(is.na(activity$steps))
activity_copy <- activity
for (int in avg_step_per_interval$interval){
print(avg_step_per_interval[avg_step_per_interval$interval==int])
}
for (int in avg_step_per_interval$interval){
print(with(avg_step_per_interval, avg_steps[interval==int]))
}
with(avg_step_per_interval, plot(interval, avg_steps, type = "l", xlab = "Date", ylab = "Average number of steps"))
for (int in avg_step_per_interval$interval){
with(avg_step_per_interval, avg_steps[interval==int])
}
for (int in avg_step_per_interval$interval){
activity$steps[is.na(activity$steps) & activity$interval == int] = with(avg_step_per_interval, avg_steps[interval==int])
}
activity <- activity_copy
activity_copy <- activity
activity <- activity_copy
activity_impute <- activity
for (int in avg_step_per_interval$interval){
activity_impute$steps[is.na(activity_impute$steps) & activity_impute$interval == int] = with(avg_step_per_interval, avg_steps[interval==int])
}
sum(is.na(activity_impute$steps))
total_step_per_day_impute <- activity_impute %>% group_by(date) %>% summarize(total_steps = sum(steps, na.rm = TRUE))
hist(total_step_per_day_impute$total_steps)
summary(total_step_per_day_impute$total_steps)
summary(total_step_per_day$total_steps)
weekdays(activity_impute$date)
?ifelse
activity_impute <- transform(activity_impute, weekDayorEnd = ifelse(weekdays(date) == "Saturday" | weekdays(date) == "Sunday", "weekend", "weekday" ))
head(activity_impute)
tail(activity_impute)
table(activity_impute$weekDayorEnd)
table(weekdays((activity_impute$date)))
avg_step_per_interval_weekDayorEnd <- activity_impute %>% group_by(interval, weekDayorEnd) %>% summarize(avg_step = mean(steps))
avg_step_per_interval_weekDayorEnd
xyplot(avg_step ~ interval | weekDayorEnd, data = avg_step_per_interval_weekDayorEnd)
library(lattice)
xyplot(avg_step ~ interval | weekDayorEnd, data = avg_step_per_interval_weekDayorEnd)
?xyplot
xyplot(avg_step ~ interval | weekDayorEnd, data = avg_step_per_interval_weekDayorEnd, layout = c(2,1), type = 'l')
xyplot(avg_step ~ interval | weekDayorEnd, data = avg_step_per_interval_weekDayorEnd, layout = c(1,2), type = 'l')
The total number of steps taken per day is `r total_step_per_day`
with(avg_step_per_interval, interval[which(avg_steps == max(avg_steps))])
activity_impute <- activity
# use mean of that 5 minute interval to impute the missing values
# iterate over all 288 5-minute intervals and impute
for (int in avg_step_per_interval$interval){
activity_impute$steps[is.na(activity_impute$steps) & activity_impute$interval == int] = with(avg_step_per_interval, avg_steps[interval==int])
}
sum(is.na(activity_impute$steps))
total_mean_new
total_mean_new <- mean(total_step_per_day_impute$total_steps)
total_mean_new
total_median_new <- median(total_step_per_day_impute$total_steps)
total_median_new
